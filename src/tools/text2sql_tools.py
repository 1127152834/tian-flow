# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
Text2SQLå·¥å…·

ä¸ºæ™ºèƒ½ä½“æä¾›è‡ªç„¶è¯­è¨€è½¬SQLæŸ¥è¯¢åŠŸèƒ½
"""

import json
import logging
import asyncio
import pandas as pd
from typing import Dict, Any, Optional, List, Annotated
from datetime import datetime

from langchain_core.tools import tool
from src.database import get_db_session
from src.tools.decorators import log_io
from src.services.text2sql import Text2SQLService
from src.models.text2sql import SQLGenerationRequest, SQLExecutionRequest
from src.services.websocket.progress_manager import progress_ws_manager

logger = logging.getLogger(__name__)


class ToolResult:
    """ç»Ÿä¸€çš„å·¥å…·è¿”å›å€¼ç»“æ„"""
    
    def __init__(
        self, 
        success: bool, 
        message: str, 
        data: Any = None, 
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        self.success = success
        self.message = message
        self.data = data
        self.error = error
        self.metadata = metadata or {}
        self.timestamp = datetime.now().isoformat()
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps({
            "success": self.success,
            "message": self.message,
            "data": self.data,
            "error": self.error,
            "metadata": self.metadata,
            "timestamp": self.timestamp
        }, ensure_ascii=False, indent=2)


def _auto_generate_chart_config(data: List[Dict], title: str = "æŸ¥è¯¢ç»“æœå›¾è¡¨") -> Optional[Dict]:
    """
    æ ¹æ®æŸ¥è¯¢ç»“æœæ•°æ®è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨é…ç½®

    Args:
        data: æŸ¥è¯¢ç»“æœæ•°æ®åˆ—è¡¨
        title: å›¾è¡¨æ ‡é¢˜

    Returns:
        å›¾è¡¨é…ç½®å­—å…¸ï¼Œå¦‚æœä¸é€‚åˆç”Ÿæˆå›¾è¡¨åˆ™è¿”å›None
    """
    if not data or len(data) < 2:
        return None

    try:
        df = pd.DataFrame(data)

        # æ£€æµ‹æ•°å€¼åˆ—å’Œåˆ†ç±»åˆ—
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()

        # å¦‚æœæ²¡æœ‰æ•°å€¼åˆ—ï¼Œä¸ç”Ÿæˆå›¾è¡¨
        if not numeric_cols:
            return None

        # æ£€æµ‹æ—¶é—´ç›¸å…³åˆ—
        time_cols = [col for col in df.columns if any(keyword in col.lower()
                    for keyword in ['time', 'date', 'æ—¶é—´', 'æ—¥æœŸ', 'created', 'updated', 'year', 'month', 'day'])]

        # æ ¹æ®æ•°æ®ç‰¹å¾é€‰æ‹©åˆé€‚çš„å›¾è¡¨ç±»å‹
        chart_config = None

        # æƒ…å†µ1ï¼šæœ‰æ—¶é—´åˆ— -> æŠ˜çº¿å›¾ï¼ˆæ—¶é—´åºåˆ—ï¼‰
        if time_cols and len(numeric_cols) >= 1:
            chart_config = {
                "type": "LineChart",
                "title": title,
                "width": 800,
                "height": 400,
                "data": data,
                "xAxis": {"dataKey": time_cols[0], "type": "category"},
                "yAxis": {"type": "number"},
                "lines": [{
                    "dataKey": numeric_cols[0],
                    "stroke": "#8884d8",
                    "type": "monotone",
                    "strokeWidth": 2
                }],
                "tooltip": {"active": True},
                "legend": True
            }

        # æƒ…å†µ2ï¼šæœ‰åˆ†ç±»åˆ—å’Œæ•°å€¼åˆ— -> æŸ±çŠ¶å›¾
        elif categorical_cols and numeric_cols:
            chart_config = {
                "type": "BarChart",
                "title": title,
                "width": 800,
                "height": 400,
                "data": data,
                "xAxis": {"dataKey": categorical_cols[0], "type": "category"},
                "yAxis": {"type": "number"},
                "bars": [{"dataKey": numeric_cols[0], "fill": "#8884d8"}],
                "tooltip": {"active": True},
                "legend": True
            }

        # æƒ…å†µ3ï¼šåªæœ‰æ•°å€¼æ•°æ®ï¼Œæ•°æ®é‡é€‚ä¸­ -> å¸¦ç´¢å¼•çš„æŸ±çŠ¶å›¾
        elif len(numeric_cols) >= 1 and len(df) <= 50:
            # ä¸ºæ•°æ®æ·»åŠ åºå·ç´¢å¼•
            data_with_index = []
            for i, row in enumerate(data):
                row_with_index = {"åºå·": f"ç¬¬{i+1}é¡¹", **row}
                data_with_index.append(row_with_index)

            chart_config = {
                "type": "BarChart",
                "title": title,
                "width": 800,
                "height": 400,
                "data": data_with_index,
                "xAxis": {"dataKey": "åºå·", "type": "category"},
                "yAxis": {"type": "number"},
                "bars": [{"dataKey": numeric_cols[0], "fill": "#8884d8"}],
                "tooltip": {"active": True},
                "legend": True
            }

        # æƒ…å†µ4ï¼šå¦‚æœæœ‰ä¸¤ä¸ªæ•°å€¼åˆ—ï¼Œå¯ä»¥è€ƒè™‘æ•£ç‚¹å›¾
        elif len(numeric_cols) >= 2 and len(df) <= 100:
            chart_config = {
                "type": "ScatterChart",
                "title": title,
                "width": 800,
                "height": 400,
                "data": data,
                "xAxis": {"dataKey": numeric_cols[0], "type": "number", "name": numeric_cols[0]},
                "yAxis": {"dataKey": numeric_cols[1], "type": "number", "name": numeric_cols[1]},
                "scatter": {"dataKey": numeric_cols[1], "fill": "#8884d8"},
                "tooltip": {"active": True},
                "legend": True
            }

        return chart_config

    except Exception as e:
        logger.warning(f"è‡ªåŠ¨å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        return None


async def _push_chart_async(chart_config: Dict, thread_id: str = None):
    """å¼‚æ­¥æ¨é€å›¾è¡¨åˆ°å‰ç«¯"""
    try:
        await progress_ws_manager.send_chart_data(chart_config, thread_id)
        logger.info(f"å›¾è¡¨å·²å¼‚æ­¥æ¨é€: {chart_config.get('title', 'Unknown')}")
    except Exception as e:
        logger.error(f"å¼‚æ­¥å›¾è¡¨æ¨é€å¤±è´¥: {e}")


@tool
@log_io
def text2sql_query(
    question: Annotated[str, "è‡ªç„¶è¯­è¨€é—®é¢˜"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“IDï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤æ•°æ®åº“"] = None,
    execute_sql: Annotated[bool, "æ˜¯å¦æ‰§è¡Œç”Ÿæˆçš„SQL"] = True
) -> str:
    """
    æ‰§è¡ŒText2SQLæŸ¥è¯¢
    
    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢å¹¶å¯é€‰æ‹©æ‰§è¡Œã€‚
    æ”¯æŒæŒ‡å®šç›®æ ‡æ•°æ®åº“ï¼Œè¿”å›SQLè¯­å¥å’ŒæŸ¥è¯¢ç»“æœã€‚
    """
    try:
        logger.info(f"ğŸ” Text2SQLæŸ¥è¯¢: {question[:100]}...")
        
        # ä½¿ç”¨çœŸå®çš„Text2SQLæœåŠ¡
        text2sql_service = Text2SQLService()

        # åˆ›å»ºSQLç”Ÿæˆè¯·æ±‚
        request = SQLGenerationRequest(
            question=question,
            datasource_id=database_id or 1,  # ä½¿ç”¨é»˜è®¤æ•°æ®åº“ID
            include_explanation=True
        )

        # ç”ŸæˆSQL
        generation_result = asyncio.run(text2sql_service.generate_sql(request))

        generated_sql = generation_result.generated_sql
        confidence = generation_result.confidence_score
        explanation = generation_result.explanation or f"åŸºäºé—®é¢˜'{question}'ç”Ÿæˆçš„SQLæŸ¥è¯¢"
        
        if not execute_sql:
            return ToolResult(
                success=True,
                message="SQLç”ŸæˆæˆåŠŸ",
                data={
                    "sql": generated_sql,
                    "confidence": confidence,
                    "explanation": explanation
                },
                metadata={
                    "question": question,
                    "database_id": database_id,
                    "executed": False
                }
            ).to_json()
        
        # æ‰§è¡ŒSQL
        execution_request = SQLExecutionRequest(
            query_id=generation_result.query_id
        )

        execution_result = asyncio.run(text2sql_service.execute_sql(execution_request))

        if execution_result.status.value == "success":
            results = execution_result.result_data or []
            row_count = execution_result.result_rows or 0
        else:
            # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœä½†ä¿ç•™SQL
            results = []
            row_count = 0
        
        return ToolResult(
            success=True,
            message="Text2SQLæŸ¥è¯¢æˆåŠŸ",
            data={
                "sql": generated_sql,
                "confidence": confidence,
                "explanation": explanation,
                "results": results,
                "row_count": row_count
            },
            metadata={
                "question": question,
                "database_id": database_id,
                "execution_time": "0.05s",
                "executed": True
            }
        ).to_json()
    
    except Exception as e:
        logger.error(f"âŒ Text2SQLæŸ¥è¯¢å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="Text2SQLæŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"question": question, "database_id": database_id}
        ).to_json()


@tool
@log_io
def generate_sql_only(
    question: Annotated[str, "è‡ªç„¶è¯­è¨€é—®é¢˜"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“ID"] = None
) -> str:
    """
    ä»…ç”ŸæˆSQLè¯­å¥

    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œä½†ä¸æ‰§è¡Œã€‚
    é€‚ç”¨äºéœ€è¦äººå·¥å®¡æ ¸SQLçš„åœºæ™¯ã€‚
    """
    try:
        logger.info(f"ğŸ”§ ç”ŸæˆSQL: {question[:100]}...")

        # ä½¿ç”¨çœŸå®çš„Text2SQLæœåŠ¡
        text2sql_service = Text2SQLService()

        # åˆ›å»ºSQLç”Ÿæˆè¯·æ±‚
        request = SQLGenerationRequest(
            question=question,
            datasource_id=database_id or 1,  # ä½¿ç”¨é»˜è®¤æ•°æ®åº“ID
            include_explanation=True
        )

        # ç”ŸæˆSQLï¼ˆä¸æ‰§è¡Œï¼‰
        generation_result = asyncio.run(text2sql_service.generate_sql(request))

        generated_sql = generation_result.generated_sql
        confidence = generation_result.confidence_score
        explanation = generation_result.explanation or f"åŸºäºé—®é¢˜'{question}'ç”Ÿæˆçš„SQLæŸ¥è¯¢"

        # è·å–ç›¸ä¼¼çš„SQLç¤ºä¾‹ä½œä¸ºå‚è€ƒ
        similar_examples = []
        try:
            # å°è¯•è·å–ç›¸ä¼¼çš„è®­ç»ƒç¤ºä¾‹
            from src.services.vanna.service_manager import vanna_service_manager
            vanna_result = asyncio.run(vanna_service_manager.generate_sql(
                datasource_id=database_id or 1,
                question=question
            ))

            if vanna_result.get("success") and vanna_result.get("similar_sqls"):
                similar_examples = vanna_result["similar_sqls"][:3]  # å–å‰3ä¸ªç›¸ä¼¼ç¤ºä¾‹

        except Exception as e:
            logger.warning(f"è·å–ç›¸ä¼¼ç¤ºä¾‹å¤±è´¥: {e}")

        return ToolResult(
            success=True,
            message="SQLç”ŸæˆæˆåŠŸ",
            data={
                "sql": generated_sql,
                "confidence": confidence,
                "explanation": explanation,
                "similar_examples": similar_examples,
                "generation_method": "text2sql_service"
            },
            metadata={
                "question": question,
                "database_id": database_id,
                "query_id": generation_result.query_id,
                "datasource_id": generation_result.datasource_id
            }
        ).to_json()

    except Exception as e:
        logger.error(f"âŒ SQLç”Ÿæˆå¼‚å¸¸: {e}")

        # å¦‚æœçœŸå®æœåŠ¡å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„å…³é”®è¯æ˜ å°„ä½œä¸ºåå¤‡
        try:
            logger.info("ä½¿ç”¨åå¤‡SQLç”Ÿæˆæ–¹æ³•...")

            # ç®€å•çš„å…³é”®è¯æ˜ å°„
            keywords_mapping = {
                "ç”¨æˆ·": "users",
                "è®¢å•": "orders",
                "äº§å“": "products",
                "é”€å”®": "sales",
                "åº“å­˜": "inventory",
                "è¡¨": "tables",
                "æ•°æ®åº“": "database"
            }

            table_name = "data"
            for keyword, table in keywords_mapping.items():
                if keyword in question:
                    table_name = table
                    break

            # ç”ŸæˆåŸºç¡€SQL
            if "ç»Ÿè®¡" in question or "æ•°é‡" in question or "æ€»è®¡" in question or "å¤šå°‘" in question:
                if "è¡¨" in question:
                    generated_sql = "SELECT COUNT(*) as table_count FROM information_schema.tables WHERE table_schema = DATABASE()"
                else:
                    generated_sql = f"SELECT COUNT(*) as total_count FROM {table_name}"
            elif "æœ€æ–°" in question or "æœ€è¿‘" in question:
                generated_sql = f"SELECT * FROM {table_name} ORDER BY created_at DESC LIMIT 10"
            elif "æ‰€æœ‰" in question or "å…¨éƒ¨" in question:
                if "è¡¨" in question:
                    generated_sql = "SELECT table_name FROM information_schema.tables WHERE table_schema = DATABASE() ORDER BY table_name"
                else:
                    generated_sql = f"SELECT * FROM {table_name} LIMIT 10"
            else:
                generated_sql = f"SELECT * FROM {table_name} LIMIT 10"

            confidence = 0.6  # é™ä½ç½®ä¿¡åº¦ï¼Œå› ä¸ºæ˜¯åå¤‡æ–¹æ³•
            explanation = f"ä½¿ç”¨å…³é”®è¯åˆ†æç”Ÿæˆçš„SQLæŸ¥è¯¢ï¼ˆåå¤‡æ–¹æ³•ï¼‰ï¼Œç›®æ ‡è¡¨: {table_name}"

            return ToolResult(
                success=True,
                message="SQLç”ŸæˆæˆåŠŸï¼ˆä½¿ç”¨åå¤‡æ–¹æ³•ï¼‰",
                data={
                    "sql": generated_sql,
                    "confidence": confidence,
                    "explanation": explanation,
                    "suggested_table": table_name,
                    "generation_method": "fallback_keyword_mapping"
                },
                metadata={
                    "question": question,
                    "database_id": database_id,
                    "fallback_reason": str(e)
                }
            ).to_json()

        except Exception as fallback_error:
            logger.error(f"âŒ åå¤‡SQLç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
            return ToolResult(
                success=False,
                message="SQLç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
                error=str(e),
                metadata={"question": question, "database_id": database_id}
            ).to_json()


@tool
@log_io
def smart_text2sql_query(
    question: Annotated[str, "è‡ªç„¶è¯­è¨€é—®é¢˜"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“IDï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤æ•°æ®åº“"] = None,
    auto_chart: Annotated[bool, "æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨"] = True,
    chart_title: Annotated[str, "å›¾è¡¨æ ‡é¢˜"] = ""
) -> str:
    """
    æ™ºèƒ½Text2SQLæŸ¥è¯¢å·¥å…· - æ”¯æŒè‡ªåŠ¨å›¾è¡¨ç”Ÿæˆ

    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢å¹¶æ‰§è¡Œï¼Œå¦‚æœç»“æœé€‚åˆå¯è§†åŒ–ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆå›¾è¡¨å¹¶æ¨é€åˆ°å‰ç«¯ã€‚
    å›¾è¡¨ç”Ÿæˆæ˜¯å¼‚æ­¥çš„ï¼Œä¸ä¼šé˜»å¡æŸ¥è¯¢ç»“æœè¿”å›ï¼Œç¡®ä¿å¿«é€Ÿå“åº”ç”¨æˆ·ã€‚
    """
    try:
        logger.info(f"ğŸ§  æ™ºèƒ½Text2SQLæŸ¥è¯¢: {question[:100]}...")

        # ä½¿ç”¨Text2SQLæœåŠ¡
        text2sql_service = Text2SQLService()

        # åˆ›å»ºSQLç”Ÿæˆè¯·æ±‚
        request = SQLGenerationRequest(
            question=question,
            datasource_id=database_id or 8,  # é»˜è®¤ä½¿ç”¨å‚²é›·ä»“å‚¨ä¸­å¿ƒåº“
            include_explanation=True
        )

        # ç”ŸæˆSQL - ä½¿ç”¨åŒæ­¥æ–¹æ³•é¿å…äº‹ä»¶å¾ªç¯é—®é¢˜
        import threading

        def run_async_in_thread(coro):
            """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°"""
            result = None
            exception = None

            def target():
                nonlocal result, exception
                try:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    result = loop.run_until_complete(coro)
                except Exception as e:
                    exception = e
                finally:
                    loop.close()

            thread = threading.Thread(target=target)
            thread.start()
            thread.join()

            if exception:
                raise exception
            return result

        generation_result = run_async_in_thread(text2sql_service.generate_sql(request))

        generated_sql = generation_result.generated_sql
        confidence = generation_result.confidence_score
        explanation = generation_result.explanation or f"åŸºäºé—®é¢˜'{question}'ç”Ÿæˆçš„SQLæŸ¥è¯¢"

        # æ‰§è¡ŒSQL
        execution_request = SQLExecutionRequest(
            query_id=generation_result.query_id
        )

        execution_result = run_async_in_thread(text2sql_service.execute_sql(execution_request))

        if execution_result.status.value == "success":
            results = execution_result.result_data or []
            row_count = execution_result.result_rows or 0
        else:
            results = []
            row_count = 0

        # æ„å»ºåŸºæœ¬å“åº”æ•°æ®
        response_data = {
            "sql": generated_sql,
            "confidence": confidence,
            "explanation": explanation,
            "results": results[:10] if results else [],  # åªè¿”å›å‰10è¡Œç»™æ™ºèƒ½ä½“æŸ¥çœ‹
            "total_rows": row_count,
            "columns": list(results[0].keys()) if results else []
        }

        # æ„å»ºå“åº”æ¶ˆæ¯
        if row_count == 0:
            message = f"æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›æ•°æ®ã€‚ç”Ÿæˆçš„SQL: {generated_sql}"
        elif row_count <= 10:
            message = f"æŸ¥è¯¢æˆåŠŸï¼è¿”å› {row_count} è¡Œæ•°æ®"
        else:
            message = f"æŸ¥è¯¢æˆåŠŸï¼è¿”å› {row_count} è¡Œæ•°æ®ï¼ˆæ˜¾ç¤ºå‰10è¡Œï¼‰"

        # å¼‚æ­¥å›¾è¡¨ç”Ÿæˆï¼ˆä¸é˜»å¡å“åº”ï¼‰
        if auto_chart and results and row_count >= 2:
            # ç¡®å®šå›¾è¡¨æ ‡é¢˜
            final_chart_title = chart_title or f"æŸ¥è¯¢ç»“æœ: {question[:30]}..."

            # ç”Ÿæˆå›¾è¡¨é…ç½®
            chart_config = _auto_generate_chart_config(results, final_chart_title)

            if chart_config:
                # å¼‚æ­¥æ¨é€å›¾è¡¨ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
                try:
                    # å°è¯•åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­åˆ›å»ºä»»åŠ¡
                    asyncio.create_task(_push_chart_async(chart_config))
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåœ¨æ–°çº¿ç¨‹ä¸­æ¨é€
                    threading.Thread(
                        target=lambda: run_async_in_thread(_push_chart_async(chart_config)),
                        daemon=True
                    ).start()

                message += f"ï¼Œ{chart_config['type']}å›¾è¡¨æ­£åœ¨ç”Ÿæˆä¸­..."
                response_data["chart_info"] = {
                    "type": chart_config["type"],
                    "status": "generating",
                    "title": final_chart_title
                }
            else:
                message += "ï¼ˆæ•°æ®ä¸é€‚åˆå›¾è¡¨å±•ç¤ºï¼‰"
                response_data["chart_info"] = {"status": "not_suitable"}
        elif auto_chart:
            response_data["chart_info"] = {"status": "disabled", "reason": "æ•°æ®é‡ä¸è¶³"}

        return ToolResult(
            success=True,
            message=message,
            data=response_data,
            metadata={
                "question": question,
                "database_id": database_id,
                "execution_time": execution_result.execution_time if hasattr(execution_result, 'execution_time') else "0.05s",
                "auto_chart": auto_chart,
                "query_id": generation_result.query_id
            }
        ).to_json()

    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½Text2SQLæŸ¥è¯¢å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="æ™ºèƒ½Text2SQLæŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"question": question, "database_id": database_id}
        ).to_json()


@tool
@log_io
def get_training_examples(
    keyword: Annotated[Optional[str], "å…³é”®è¯è¿‡æ»¤"] = None,
    limit: Annotated[int, "è¿”å›æ•°é‡é™åˆ¶"] = 10
) -> str:
    """
    è·å–Text2SQLè®­ç»ƒç¤ºä¾‹
    
    ä»vanna_embeddingsè¡¨ä¸­è·å–è®­ç»ƒç¤ºä¾‹ï¼Œç”¨äºå‚è€ƒå’Œå­¦ä¹ ã€‚
    """
    try:
        logger.info(f"ğŸ“š è·å–è®­ç»ƒç¤ºä¾‹: keyword={keyword}, limit={limit}")
        
        session = next(get_db_session())
        
        try:
            from sqlalchemy import text
            
            # æ„å»ºæŸ¥è¯¢ - åŒ…å« datasource_id å­—æ®µï¼Œç¡®ä¿è·å–æ‰€æœ‰æ•°æ®æºçš„ç¤ºä¾‹
            if keyword:
                query = text("""
                    WITH ranked_examples AS (
                        SELECT datasource_id, question, content, sql_query, content_type, table_name,
                               ROW_NUMBER() OVER (PARTITION BY datasource_id ORDER BY created_at DESC) as rn
                        FROM text2sql.vanna_embeddings
                        WHERE question ILIKE :keyword OR content ILIKE :keyword
                    )
                    SELECT datasource_id, question, content, sql_query, content_type, table_name
                    FROM ranked_examples
                    WHERE rn <= :per_datasource_limit
                    ORDER BY datasource_id, rn
                """)
                # æ¯ä¸ªæ•°æ®æºæœ€å¤šè¿”å› limit/3 ä¸ªç¤ºä¾‹ï¼Œç¡®ä¿å¤šæ ·æ€§ï¼Œè‡³å°‘ 5 ä¸ª
                per_datasource_limit = max(5, limit // 3)
                result = session.execute(query, {"keyword": f"%{keyword}%", "per_datasource_limit": per_datasource_limit})
            else:
                query = text("""
                    WITH ranked_examples AS (
                        SELECT datasource_id, question, content, sql_query, content_type, table_name,
                               ROW_NUMBER() OVER (PARTITION BY datasource_id ORDER BY created_at DESC) as rn
                        FROM text2sql.vanna_embeddings
                    )
                    SELECT datasource_id, question, content, sql_query, content_type, table_name
                    FROM ranked_examples
                    WHERE rn <= :per_datasource_limit
                    ORDER BY datasource_id, rn
                    LIMIT :limit
                """)
                # æ¯ä¸ªæ•°æ®æºæœ€å¤šè¿”å› limit/3 ä¸ªç¤ºä¾‹ï¼Œç¡®ä¿å¤šæ ·æ€§ï¼Œè‡³å°‘ 5 ä¸ª
                per_datasource_limit = max(5, limit // 3)
                result = session.execute(query, {"per_datasource_limit": per_datasource_limit, "limit": limit})

            examples = []
            for row in result.fetchall():
                example = {
                    "datasource_id": row.datasource_id,
                    "question": row.question,
                    "content": row.content,
                    "sql_query": row.sql_query,
                    "content_type": row.content_type,
                    "table_name": row.table_name
                }
                examples.append(example)
            
            return ToolResult(
                success=True,
                message=f"æ‰¾åˆ° {len(examples)} ä¸ªè®­ç»ƒç¤ºä¾‹",
                data={
                    "examples": examples,
                    "total_count": len(examples)
                },
                metadata={
                    "keyword_filter": keyword,
                    "limit": limit
                }
            ).to_json()
        
        finally:
            session.close()
    
    except Exception as e:
        logger.error(f"âŒ è·å–è®­ç»ƒç¤ºä¾‹å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="è·å–è®­ç»ƒç¤ºä¾‹è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"keyword": keyword, "limit": limit}
        ).to_json()


@tool
@log_io
def validate_sql(
    sql: Annotated[str, "è¦éªŒè¯çš„SQLè¯­å¥"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“ID"] = None
) -> str:
    """
    éªŒè¯SQLè¯­å¥
    
    æ£€æŸ¥SQLè¯­å¥çš„è¯­æ³•æ­£ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œä¸æ‰§è¡ŒæŸ¥è¯¢ã€‚
    """
    try:
        logger.info(f"ğŸ” éªŒè¯SQL: {sql[:100]}...")
        
        # åŸºæœ¬çš„SQLå®‰å…¨æ£€æŸ¥
        dangerous_keywords = [
            "DROP", "DELETE", "UPDATE", "INSERT", "ALTER", 
            "CREATE", "TRUNCATE", "EXEC", "EXECUTE"
        ]
        
        sql_upper = sql.upper()
        found_dangerous = [kw for kw in dangerous_keywords if kw in sql_upper]
        
        if found_dangerous:
            return ToolResult(
                success=False,
                message="SQLåŒ…å«å±é™©æ“ä½œ",
                error=f"å‘ç°å±é™©å…³é”®è¯: {', '.join(found_dangerous)}",
                data={"sql": sql, "dangerous_keywords": found_dangerous}
            ).to_json()
        
        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
        if not sql.strip().upper().startswith("SELECT"):
            return ToolResult(
                success=False,
                message="åªæ”¯æŒSELECTæŸ¥è¯¢",
                error="SQLå¿…é¡»ä»¥SELECTå¼€å¤´",
                data={"sql": sql}
            ).to_json()
        
        # TODO: æ›´è¯¦ç»†çš„SQLè¯­æ³•éªŒè¯
        # å¯ä»¥é›†æˆSQLè§£æå™¨è¿›è¡Œæ›´ä¸¥æ ¼çš„éªŒè¯
        
        return ToolResult(
            success=True,
            message="SQLéªŒè¯é€šè¿‡",
            data={
                "sql": sql,
                "is_safe": True,
                "query_type": "SELECT"
            },
            metadata={
                "database_id": database_id,
                "validation_rules": ["å®‰å…¨å…³é”®è¯æ£€æŸ¥", "æŸ¥è¯¢ç±»å‹æ£€æŸ¥"]
            }
        ).to_json()
    
    except Exception as e:
        logger.error(f"âŒ SQLéªŒè¯å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="SQLéªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"sql": sql, "database_id": database_id}
        ).to_json()
