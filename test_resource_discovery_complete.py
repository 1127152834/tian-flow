#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èµ„æºå‘ç°æ¨¡å—å®Œæ•´æµ‹è¯•

æµ‹è¯•æ•´ä¸ªèµ„æºå‘ç°æ¨¡å—çš„å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…æ‹¬å®æ—¶æ›´æ–°
"""

import asyncio
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹"""
    print("\nğŸš€ æµ‹è¯•å®Œæ•´çš„èµ„æºå‘ç°å·¥ä½œæµç¨‹...")
    
    try:
        from src.tools.resource_discovery import (
            sync_system_resources,
            discover_resources,
            get_resource_statistics,
            search_resources_by_type
        )
        
        # 1. åˆå§‹åŒ– - å¼ºåˆ¶å…¨é‡åŒæ­¥
        print("\n1ï¸âƒ£ åˆå§‹åŒ–ç³»ç»Ÿèµ„æº...")
        sync_result = await sync_system_resources(force_full_sync=True)
        
        if not sync_result.get("success"):
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {sync_result.get('message')}")
            return False
        
        print(f"âœ… åˆå§‹åŒ–å®Œæˆ: å‘ç° {sync_result.get('total_discovered', 0)} ä¸ªèµ„æº")
        
        # 2. è·å–ç³»ç»Ÿç»Ÿè®¡
        print("\n2ï¸âƒ£ è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯...")
        stats_result = await get_resource_statistics()
        
        if stats_result.get("success"):
            summary = stats_result.get("summary", {})
            print(f"âœ… ç³»ç»Ÿç»Ÿè®¡:")
            print(f"   æ€»èµ„æºæ•°: {summary.get('total_resources', 0)}")
            print(f"   æ´»è·ƒèµ„æºæ•°: {summary.get('active_resources', 0)}")
            print(f"   å‘é‡åŒ–ç‡: {summary.get('vectorization_rate', 0)}%")
            
            by_type = stats_result.get("by_type", {})
            for resource_type, stats in by_type.items():
                print(f"   {resource_type}: {stats['total']} ä¸ª")
        else:
            print(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {stats_result.get('error')}")
        
        # 3. æµ‹è¯•å„ç§æŸ¥è¯¢åœºæ™¯
        print("\n3ï¸âƒ£ æµ‹è¯•æ™ºèƒ½èµ„æºå‘ç°...")
        
        test_scenarios = [
            {
                "query": "æŸ¥è¯¢æ•°æ®åº“ä¸­çš„ç”¨æˆ·ä¿¡æ¯",
                "expected_types": ["database", "text2sql"],
                "description": "æ•°æ®åº“æŸ¥è¯¢åœºæ™¯"
            },
            {
                "query": "è°ƒç”¨å¤–éƒ¨APIè·å–æ•°æ®",
                "expected_types": ["api"],
                "description": "APIè°ƒç”¨åœºæ™¯"
            },
            {
                "query": "æ‰§è¡ŒSQLæŸ¥è¯¢ç»Ÿè®¡",
                "expected_types": ["database", "text2sql"],
                "description": "SQLæ‰§è¡Œåœºæ™¯"
            },
            {
                "query": "è·å–ç³»ç»Ÿå·¥å…·åˆ—è¡¨",
                "expected_types": ["tool"],
                "description": "å·¥å…·æŸ¥è¯¢åœºæ™¯"
            }
        ]
        
        successful_scenarios = 0
        
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\n   åœºæ™¯ {i}: {scenario['description']}")
            print(f"   æŸ¥è¯¢: '{scenario['query']}'")
            
            result = await discover_resources(
                user_query=scenario["query"],
                max_results=3,
                min_confidence=0.1
            )
            
            if result.get("success"):
                matches = result.get("matches", [])
                print(f"   æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…èµ„æº:")
                
                found_types = set()
                for match in matches:
                    resource_type = match.get("resource_type")
                    resource_name = match.get("resource_name")
                    confidence = match.get("confidence_score", 0)
                    print(f"     - {resource_name} ({resource_type}, ç½®ä¿¡åº¦: {confidence:.3f})")
                    found_types.add(resource_type)
                
                # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†é¢„æœŸçš„èµ„æºç±»å‹
                expected_found = any(t in found_types for t in scenario["expected_types"])
                if expected_found or len(matches) > 0:
                    print(f"   âœ… åœºæ™¯æµ‹è¯•é€šè¿‡")
                    successful_scenarios += 1
                else:
                    print(f"   âš ï¸  æœªæ‰¾åˆ°é¢„æœŸçš„èµ„æºç±»å‹: {scenario['expected_types']}")
            else:
                print(f"   âŒ æŸ¥è¯¢å¤±è´¥: {result.get('error')}")
        
        print(f"\n   æ™ºèƒ½å‘ç°æµ‹è¯•ç»“æœ: {successful_scenarios}/{len(test_scenarios)} ä¸ªåœºæ™¯æˆåŠŸ")
        
        # 4. æµ‹è¯•æŒ‰ç±»å‹æœç´¢
        print("\n4ï¸âƒ£ æµ‹è¯•æŒ‰ç±»å‹æœç´¢...")
        
        resource_types = ["database", "api", "text2sql"]
        type_search_success = 0
        
        for resource_type in resource_types:
            result = await search_resources_by_type(resource_type=resource_type, limit=5)
            
            if result.get("success"):
                resources = result.get("resources", [])
                print(f"   {resource_type}: æ‰¾åˆ° {len(resources)} ä¸ªèµ„æº")
                type_search_success += 1
            else:
                print(f"   {resource_type}: æœç´¢å¤±è´¥")
        
        print(f"   ç±»å‹æœç´¢æµ‹è¯•ç»“æœ: {type_search_success}/{len(resource_types)} ä¸ªç±»å‹æˆåŠŸ")
        
        # 5. æµ‹è¯•å¢é‡åŒæ­¥
        print("\n5ï¸âƒ£ æµ‹è¯•å¢é‡åŒæ­¥...")
        
        incremental_result = await sync_system_resources(force_full_sync=False)
        
        if incremental_result.get("success"):
            print(f"âœ… å¢é‡åŒæ­¥æˆåŠŸ")
            processed_changes = incremental_result.get("processed_changes", {})
            print(f"   å¤„ç†çš„å˜æ›´: {processed_changes}")
        else:
            print(f"âŒ å¢é‡åŒæ­¥å¤±è´¥: {incremental_result.get('message')}")
        
        # 6. è®¡ç®—æ€»ä½“æˆåŠŸç‡
        total_tests = 5
        successful_tests = sum([
            1 if sync_result.get("success") else 0,
            1 if stats_result.get("success") else 0,
            1 if successful_scenarios >= len(test_scenarios) // 2 else 0,  # è‡³å°‘ä¸€åŠåœºæ™¯æˆåŠŸ
            1 if type_search_success >= len(resource_types) // 2 else 0,   # è‡³å°‘ä¸€åŠç±»å‹æˆåŠŸ
            1 if incremental_result.get("success") else 0
        ])
        
        success_rate = successful_tests / total_tests * 100
        
        print(f"\nğŸ¯ å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸç‡: {success_rate:.0f}% ({successful_tests}/{total_tests})")
        
        return success_rate >= 80  # 80% æˆåŠŸç‡è®¤ä¸ºé€šè¿‡
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
    print("\nâš¡ æµ‹è¯•æ€§èƒ½æŒ‡æ ‡...")
    
    try:
        from src.tools.resource_discovery import discover_resources
        import time
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        test_queries = [
            "æŸ¥è¯¢ç”¨æˆ·æ•°æ®",
            "è·å–APIä¿¡æ¯", 
            "æ‰§è¡ŒSQLæŸ¥è¯¢",
            "è°ƒç”¨ç³»ç»Ÿå·¥å…·",
            "æ•°æ®åº“è¿æ¥"
        ]
        
        total_time = 0
        successful_queries = 0
        
        for query in test_queries:
            start_time = time.time()
            
            result = await discover_resources(
                user_query=query,
                max_results=3,
                min_confidence=0.1
            )
            
            end_time = time.time()
            query_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            if result.get("success"):
                successful_queries += 1
                total_time += query_time
                matches_count = len(result.get("matches", []))
                print(f"   '{query}': {query_time:.0f}ms, {matches_count} ä¸ªåŒ¹é…")
            else:
                print(f"   '{query}': æŸ¥è¯¢å¤±è´¥")
        
        if successful_queries > 0:
            avg_time = total_time / successful_queries
            print(f"\n   æ€§èƒ½ç»Ÿè®¡:")
            print(f"   å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.0f}ms")
            print(f"   æˆåŠŸæŸ¥è¯¢ç‡: {successful_queries}/{len(test_queries)}")
            
            # æ€§èƒ½è¯„ä¼°
            if avg_time < 100:
                print(f"   âœ… æ€§èƒ½ä¼˜ç§€ (< 100ms)")
            elif avg_time < 500:
                print(f"   âœ… æ€§èƒ½è‰¯å¥½ (< 500ms)")
            elif avg_time < 1000:
                print(f"   âš ï¸  æ€§èƒ½ä¸€èˆ¬ (< 1s)")
            else:
                print(f"   âŒ æ€§èƒ½è¾ƒå·® (> 1s)")
            
            return avg_time < 1000  # 1ç§’å†…è®¤ä¸ºæ€§èƒ½å¯æ¥å—
        else:
            print(f"   âŒ æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥äº†")
            return False
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    try:
        from src.tools.resource_discovery import discover_resources, search_resources_by_type
        
        error_scenarios = [
            {
                "name": "ç©ºæŸ¥è¯¢",
                "func": lambda: discover_resources(user_query="", max_results=3),
                "should_handle": True
            },
            {
                "name": "æ— æ•ˆèµ„æºç±»å‹",
                "func": lambda: search_resources_by_type(resource_type="invalid_type", limit=5),
                "should_handle": True
            },
            {
                "name": "è¶…å¤§ç»“æœæ•°",
                "func": lambda: discover_resources(user_query="test", max_results=1000),
                "should_handle": True
            }
        ]
        
        handled_errors = 0
        
        for scenario in error_scenarios:
            try:
                result = await scenario["func"]()
                
                if scenario["should_handle"]:
                    # åº”è¯¥ä¼˜é›…å¤„ç†é”™è¯¯ï¼Œè¿”å›æœ‰æ„ä¹‰çš„ç»“æœ
                    if result.get("success") is False or len(result.get("matches", [])) == 0:
                        print(f"   âœ… {scenario['name']}: é”™è¯¯è¢«æ­£ç¡®å¤„ç†")
                        handled_errors += 1
                    else:
                        print(f"   âš ï¸  {scenario['name']}: å¯èƒ½æœªæ­£ç¡®å¤„ç†è¾¹ç•Œæƒ…å†µ")
                else:
                    print(f"   âœ… {scenario['name']}: æ­£å¸¸æ‰§è¡Œ")
                    handled_errors += 1
                    
            except Exception as e:
                if scenario["should_handle"]:
                    print(f"   âŒ {scenario['name']}: æœªæ•è·å¼‚å¸¸ - {e}")
                else:
                    print(f"   âœ… {scenario['name']}: é¢„æœŸå¼‚å¸¸ - {e}")
                    handled_errors += 1
        
        success_rate = handled_errors / len(error_scenarios) * 100
        print(f"\n   é”™è¯¯å¤„ç†æµ‹è¯•ç»“æœ: {success_rate:.0f}% ({handled_errors}/{len(error_scenarios)})")
        
        return success_rate >= 80
        
    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹èµ„æºå‘ç°æ¨¡å—å®Œæ•´æµ‹è¯•...")
    print("=" * 80)
    
    start_time = datetime.now()
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("å®Œæ•´å·¥ä½œæµç¨‹", test_complete_workflow),
        ("æ€§èƒ½æŒ‡æ ‡", test_performance_metrics),
        ("é”™è¯¯å¤„ç†", test_error_handling),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*20} {test_name} {'='*20}")
            results[test_name] = await test_func()
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results[test_name] = False
    
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ èµ„æºå‘ç°æ¨¡å—å®Œæ•´æµ‹è¯•å®Œæˆ!")
    print(f"æ€»è€—æ—¶: {duration.total_seconds():.2f} ç§’")
    print("\nğŸ“‹ æµ‹è¯•ç»“æœ:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ…" if result else "âŒ"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ æµ‹è¯•æ€»ç»“: {passed}/{total} é€šè¿‡ ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼èµ„æºå‘ç°æ¨¡å—å·²å®Œå…¨å°±ç»ª")
        print("\nğŸ“ æ¨¡å—ç‰¹æ€§:")
        print("âœ… æ™ºèƒ½èµ„æºå‘ç° - åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½åŒ¹é…")
        print("âœ… å®æ—¶åŒæ­¥ - æ•°æ®åº“è§¦å‘å™¨é©±åŠ¨çš„å¢é‡æ›´æ–°")
        print("âœ… å¤šèµ„æºç±»å‹æ”¯æŒ - æ•°æ®åº“ã€APIã€å·¥å…·ã€Text2SQL")
        print("âœ… æ€§èƒ½ä¼˜åŒ– - å‘é‡ç´¢å¼•å’ŒæŸ¥è¯¢ç¼“å­˜")
        print("âœ… å·¥å…·é›†æˆ - ä¸ DeerFlow Agent æ— ç¼é›†æˆ")
        print("âœ… é”™è¯¯å¤„ç† - å¥å£®çš„å¼‚å¸¸å¤„ç†æœºåˆ¶")
        
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. é›†æˆçœŸå®çš„åµŒå…¥æœåŠ¡ (å¦‚ OpenAI Embeddings)")
        print("2. æ·»åŠ ç”¨æˆ·åé¦ˆå­¦ä¹ æœºåˆ¶")
        print("3. å®ç°æ›´å¤šèµ„æºç±»å‹æ”¯æŒ")
        print("4. æ·»åŠ å‰ç«¯ç®¡ç†ç•Œé¢")
        print("5. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³é—®é¢˜")
    
    return passed == total


if __name__ == "__main__":
    asyncio.run(main())
