# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
æ•°æ®åº“æ“ä½œå·¥å…·

ä¸ºæ™ºèƒ½ä½“æä¾›æ•°æ®åº“æŸ¥è¯¢å’Œç®¡ç†åŠŸèƒ½
"""

import json
import logging
import asyncio
from typing import Dict, Any, Optional, List, Annotated
from datetime import datetime

from langchain_core.tools import tool
from src.database import get_db_session
from src.tools.decorators import log_io
from src.services.database_datasource import DatabaseDatasourceService

logger = logging.getLogger(__name__)


class ToolResult:
    """ç»Ÿä¸€çš„å·¥å…·è¿”å›å€¼ç»“æ„"""
    
    def __init__(
        self, 
        success: bool, 
        message: str, 
        data: Any = None, 
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        self.success = success
        self.message = message
        self.data = data
        self.error = error
        self.metadata = metadata or {}
        self.timestamp = datetime.now().isoformat()
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps({
            "success": self.success,
            "message": self.message,
            "data": self.data,
            "error": self.error,
            "metadata": self.metadata,
            "timestamp": self.timestamp
        }, ensure_ascii=False, indent=2)


@tool
@log_io
def database_query(
    database_name: Annotated[str, "æ•°æ®åº“åç§°æˆ–ID"],
    query_type: Annotated[str, "æŸ¥è¯¢ç±»å‹: info|tables|schema"] = "info"
) -> str:
    """
    æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢

    æ”¯æŒå¤šç§æŸ¥è¯¢ç±»å‹ï¼šè·å–æ•°æ®åº“ä¿¡æ¯ã€è¡¨åˆ—è¡¨ã€è¡¨ç»“æ„ã€‚
    æ³¨æ„ï¼šä¸æ”¯æŒSQLæ‰§è¡Œï¼Œè¯·ä½¿ç”¨text2sql_queryå·¥å…·æ‰§è¡ŒSQLæŸ¥è¯¢ã€‚
    """
    try:
        logger.info(f"ğŸ—„ï¸ æ•°æ®åº“æŸ¥è¯¢: {database_name} - {query_type}")

        # ä½¿ç”¨çœŸå®çš„æ•°æ®åº“æ•°æ®æºæœåŠ¡
        datasource_service = DatabaseDatasourceService()

        # è·å–æ•°æ®åº“é…ç½®
        if database_name.isdigit():
            datasource = asyncio.run(datasource_service.get_datasource(int(database_name)))
        else:
            # æŒ‰åç§°æŸ¥æ‰¾éœ€è¦å…ˆåˆ—å‡ºæ‰€æœ‰æ•°æ®æº
            datasources = asyncio.run(datasource_service.list_datasources(search=database_name))
            datasource = datasources[0] if datasources else None

        if not datasource:
            return ToolResult(
                success=False,
                message=f"æ•°æ®åº“ '{database_name}' æœªæ‰¾åˆ°",
                error="DATABASE_NOT_FOUND"
            ).to_json()

        # æ ¹æ®æŸ¥è¯¢ç±»å‹æ‰§è¡Œä¸åŒæ“ä½œ
        if query_type == "info":
            return ToolResult(
                success=True,
                message=f"æ•°æ®åº“ '{datasource.name}' ä¿¡æ¯è·å–æˆåŠŸ",
                data={
                    "id": datasource.id,
                    "name": datasource.name,
                    "description": datasource.description,
                    "type": datasource.database_type.value,
                    "host": datasource.host,
                    "port": datasource.port,
                    "database": datasource.database_name
                }
            ).to_json()

        elif query_type == "tables":
            # è·å–æ•°æ®åº“ç»“æ„ä¿¡æ¯
            schema_response = asyncio.run(datasource_service.get_database_schema(datasource.id))
            if not schema_response:
                return ToolResult(
                    success=False,
                    message=f"æ— æ³•è·å–æ•°æ®åº“ '{datasource.name}' çš„è¡¨åˆ—è¡¨",
                    error="SCHEMA_EXTRACTION_FAILED"
                ).to_json()

            tables = []
            for table in schema_response.tables:
                table_info = {
                    "name": table.get("table_name", ""),
                    "schema": table.get("schema_name", ""),
                    "column_count": table.get("column_count", 0)
                }
                tables.append(table_info)

            return ToolResult(
                success=True,
                message=f"æ•°æ®åº“ '{datasource.name}' è¡¨åˆ—è¡¨è·å–æˆåŠŸ",
                data={"tables": tables, "count": len(tables)},
                metadata={"database_id": datasource.id, "total_tables": schema_response.total_tables}
            ).to_json()

        elif query_type == "schema":
            # è·å–æ•°æ®åº“ç»“æ„ä¿¡æ¯
            schema_response = asyncio.run(datasource_service.get_database_schema(datasource.id))
            if not schema_response:
                return ToolResult(
                    success=False,
                    message=f"æ— æ³•è·å–æ•°æ®åº“ '{datasource.name}' çš„ç»“æ„ä¿¡æ¯",
                    error="SCHEMA_EXTRACTION_FAILED"
                ).to_json()

            schema_info = {}
            for table in schema_response.tables:
                table_name = table.get("table_name", "")
                schema_info[table_name] = {
                    "columns": table.get("columns", []),
                    "column_count": table.get("column_count", 0),
                    "schema_name": table.get("schema_name", "")
                }

            return ToolResult(
                success=True,
                message=f"æ•°æ®åº“ '{datasource.name}' ç»“æ„ä¿¡æ¯è·å–æˆåŠŸ",
                data={"schema": schema_info, "table_count": len(schema_info)},
                metadata={"database_id": datasource.id, "total_tables": schema_response.total_tables}
            ).to_json()

        else:
            return ToolResult(
                success=False,
                message=f"ä¸æ”¯æŒçš„æŸ¥è¯¢ç±»å‹: {query_type}ã€‚æ”¯æŒçš„ç±»å‹: info, tables, schema",
                error="INVALID_QUERY_TYPE"
            ).to_json()
    
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="æ•°æ®åº“æŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"database_name": database_name, "query_type": query_type}
        ).to_json()


@tool
@log_io
def list_databases(
    enabled_only: Annotated[bool, "åªæ˜¾ç¤ºå¯ç”¨çš„æ•°æ®åº“"] = True
) -> str:
    """
    åˆ—å‡ºå¯ç”¨çš„æ•°æ®åº“
    
    è·å–ç³»ç»Ÿä¸­é…ç½®çš„æ‰€æœ‰æ•°æ®åº“è¿æ¥ä¿¡æ¯ã€‚
    """
    try:
        logger.info(f"ğŸ“‹ è·å–æ•°æ®åº“åˆ—è¡¨: enabled_only={enabled_only}")
        
        session = next(get_db_session())
        
        try:
            from sqlalchemy import text
            
            where_clause = "WHERE deleted_at IS NULL" if enabled_only else ""
            
            query = text(f"""
                SELECT id, name, description, database_type, host, port,
                       database_name, (deleted_at IS NULL) as enabled, created_at
                FROM database_management.database_datasources
                {where_clause}
                ORDER BY name
            """)
            
            result = session.execute(query)
            databases = []
            
            for row in result.fetchall():
                db_info = {
                    "id": row.id,
                    "name": row.name,
                    "description": row.description,
                    "type": row.database_type,
                    "host": row.host,
                    "port": row.port,
                    "database": row.database_name,
                    "enabled": row.enabled,
                    "created_at": row.created_at.isoformat() if row.created_at else None
                }
                databases.append(db_info)
            
            return ToolResult(
                success=True,
                message=f"æ‰¾åˆ° {len(databases)} ä¸ªæ•°æ®åº“",
                data={"databases": databases, "total_count": len(databases)},
                metadata={"enabled_only": enabled_only}
            ).to_json()
        
        finally:
            session.close()
    
    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®åº“åˆ—è¡¨å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="è·å–æ•°æ®åº“åˆ—è¡¨è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e)
        ).to_json()


@tool
@log_io
def test_database_connection(
    database_name: Annotated[str, "æ•°æ®åº“åç§°æˆ–ID"]
) -> str:
    """
    æµ‹è¯•æ•°æ®åº“è¿æ¥
    
    éªŒè¯æŒ‡å®šæ•°æ®åº“çš„è¿æ¥çŠ¶æ€å’Œå¯ç”¨æ€§ã€‚
    """
    try:
        logger.info(f"ğŸ”Œ æµ‹è¯•æ•°æ®åº“è¿æ¥: {database_name}")
        
        session = next(get_db_session())
        
        try:
            from sqlalchemy import text
            
            # æŸ¥æ‰¾æ•°æ®åº“é…ç½®
            if database_name.isdigit():
                query = text("""
                    SELECT id, name, host, port, database_name, database_type
                    FROM database_management.database_datasources 
                    WHERE id = :db_id
                """)
                result = session.execute(query, {"db_id": int(database_name)})
            else:
                query = text("""
                    SELECT id, name, host, port, database_name, database_type
                    FROM database_management.database_datasources 
                    WHERE name = :db_name
                """)
                result = session.execute(query, {"db_name": database_name})
            
            db_config = result.fetchone()
            if not db_config:
                return ToolResult(
                    success=False,
                    message=f"æ•°æ®åº“ '{database_name}' æœªæ‰¾åˆ°",
                    error="DATABASE_NOT_FOUND"
                ).to_json()
            
            # ç®€å•çš„è¿æ¥æµ‹è¯•ï¼ˆä½¿ç”¨å½“å‰è¿æ¥æ‰§è¡ŒåŸºæœ¬æŸ¥è¯¢ï¼‰
            test_query = text("SELECT 1 as test_connection")
            test_result = session.execute(test_query)
            test_row = test_result.fetchone()
            
            if test_row and test_row.test_connection == 1:
                return ToolResult(
                    success=True,
                    message=f"æ•°æ®åº“ '{db_config.name}' è¿æ¥æµ‹è¯•æˆåŠŸ",
                    data={
                        "database_id": db_config.id,
                        "database_name": db_config.name,
                        "host": db_config.host,
                        "port": db_config.port,
                        "database": db_config.database_name,
                        "type": db_config.database_type,
                        "connection_status": "success"
                    }
                ).to_json()
            else:
                return ToolResult(
                    success=False,
                    message=f"æ•°æ®åº“ '{db_config.name}' è¿æ¥æµ‹è¯•å¤±è´¥",
                    error="CONNECTION_TEST_FAILED"
                ).to_json()
        
        finally:
            session.close()
    
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="æ•°æ®åº“è¿æ¥æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"database_name": database_name}
        ).to_json()
