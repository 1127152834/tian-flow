"""
èµ„æºå‘ç°æ¨¡å— API è·¯ç”±

åŸºäº Ti-Flow çš„æ„å›¾è¯†åˆ« API è®¾è®¡ï¼Œä¸º Olight æä¾›èµ„æºå‘ç°å’ŒåŒ¹é…æ¥å£
"""

import logging
from datetime import datetime
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session

from src.database import get_db_session
from src.models.resource_discovery import (
    ResourceDiscoveryRequest,
    ResourceDiscoveryResponse,
    ResourceRegistryResponse,
    ResourceMatch,
    ResourceType,
    VectorizationStatus,
    BatchVectorizationRequest,
    BatchVectorizationResponse,
    SystemStatus,
    OperationType,
    SystemStatusType
)
from src.services.resource_discovery import (
    ResourceDiscoveryService,
    ResourceVectorizer,
    ResourceMatcher,
    ResourceSynchronizer
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/resource-discovery", tags=["Resource Discovery"])

# åˆå§‹åŒ–æœåŠ¡
discovery_service = ResourceDiscoveryService()
vectorizer = ResourceVectorizer()
matcher = ResourceMatcher()
synchronizer = ResourceSynchronizer()


@router.post("/discover", response_model=ResourceDiscoveryResponse)
async def discover_resources(
    request: ResourceDiscoveryRequest,
    session: Session = Depends(get_db_session)
):
    """
    æ™ºèƒ½èµ„æºå‘ç°

    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ‰¾åˆ°æœ€åŒ¹é…çš„ç³»ç»Ÿèµ„æº
    """
    try:
        start_time = datetime.utcnow()

        logger.info(f"ğŸ” èµ„æºå‘ç°è¯·æ±‚: '{request.user_query}'")

        # æ‰§è¡Œèµ„æºåŒ¹é…
        matches = await matcher.match_resources(
            session=session,
            user_query=request.user_query,
            top_k=request.max_results,
            resource_types=[rt.value for rt in request.resource_types] if request.resource_types else None,
            min_confidence=request.min_confidence
        )

        # è·å–æ€»èµ„æºæ•°é‡
        from sqlalchemy import text
        count_query = text("SELECT COUNT(*) FROM resource_discovery.resource_registry WHERE is_active = true")
        total_resources = session.execute(count_query).scalar()

        processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000

        response = ResourceDiscoveryResponse(
            query=request.user_query,
            matches=matches,
            total_resources=total_resources,
            processing_time_ms=processing_time,
            timestamp=datetime.utcnow()
        )

        logger.info(f"âœ… èµ„æºå‘ç°å®Œæˆ: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…èµ„æºï¼Œè€—æ—¶ {processing_time:.0f}ms")
        return response

    except Exception as e:
        logger.error(f"âŒ èµ„æºå‘ç°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"èµ„æºå‘ç°å¤±è´¥: {str(e)}")


@router.post("/test-match")
async def test_resource_matching(
    request: dict,
    session: Session = Depends(get_db_session)
):
    """
    èµ„æºå‘ç°æµ‹è¯•æ¥å£

    ç±»ä¼¼ Ti-Flow çš„æ„å›¾è¯†åˆ«æµ‹è¯•åŠŸèƒ½ï¼Œç”¨äºæµ‹è¯•èµ„æºåŒ¹é…æ•ˆæœ
    """
    try:
        import time
        start_time = time.time()

        # è§£æè¯·æ±‚å‚æ•°
        query = request.get("query", "").strip()
        top_k = request.get("top_k", 5)
        min_confidence = request.get("min_confidence", 0.1)
        resource_types = request.get("resource_types", None)

        if not query:
            raise HTTPException(status_code=400, detail="æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º")

        logger.info(f"ğŸ§ª èµ„æºåŒ¹é…æµ‹è¯•: '{query}', top_k={top_k}, min_confidence={min_confidence}")

        # æ‰§è¡Œèµ„æºåŒ¹é…
        matches = await matcher.match_resources(
            session=session,
            user_query=query,
            top_k=top_k,
            min_confidence=min_confidence,
            resource_types=resource_types
        )

        processing_time = time.time() - start_time

        # æ ¼å¼åŒ–åŒ¹é…ç»“æœ
        formatted_matches = []
        for match in matches:
            # è®¡ç®—ç½®ä¿¡åº¦çº§åˆ«
            confidence_level = "low"
            if match.confidence_score >= 0.8:
                confidence_level = "high"
            elif match.confidence_score >= 0.6:
                confidence_level = "medium"

            formatted_match = {
                "resource_id": match.resource.resource_id,
                "resource_name": match.resource.resource_name,
                "resource_type": match.resource.resource_type,
                "description": match.resource.description or "",
                "capabilities": match.resource.capabilities or [],
                "similarity_score": round(match.similarity_score, 3),
                "confidence_score": round(match.confidence_score, 3),
                "confidence": confidence_level,
                "reasoning": f"åŸºäºå‘é‡ç›¸ä¼¼åº¦åŒ¹é…ï¼Œç›¸ä¼¼åº¦: {match.similarity_score:.3f}",
                "detailed_scores": {
                    "similarity": round(match.similarity_score, 3),
                    "confidence": round(match.confidence_score, 3)
                }
            }
            formatted_matches.append(formatted_match)

        # ç¡®å®šæœ€ä½³åŒ¹é…
        best_match = formatted_matches[0] if formatted_matches else None

        response_data = {
            "query": query,
            "total_matches": len(formatted_matches),
            "matches": formatted_matches,
            "best_match": best_match,
            "processing_time": round(processing_time, 3),
            "parameters": {
                "top_k": top_k,
                "min_confidence": min_confidence,
                "resource_types": resource_types
            }
        }

        logger.info(f"âœ… èµ„æºåŒ¹é…æµ‹è¯•å®Œæˆ: æ‰¾åˆ° {len(formatted_matches)} ä¸ªåŒ¹é…ç»“æœ, è€—æ—¶ {processing_time:.3f}s")

        return {
            "success": True,
            "data": response_data
        }

    except Exception as e:
        logger.error(f"âŒ èµ„æºåŒ¹é…æµ‹è¯•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"èµ„æºåŒ¹é…æµ‹è¯•å¤±è´¥: {str(e)}")


@router.get("/resources", response_model=List[ResourceRegistryResponse])
async def list_resources(
    resource_type: Optional[ResourceType] = Query(None, description="èµ„æºç±»å‹è¿‡æ»¤"),
    is_active: Optional[bool] = Query(None, description="æ˜¯å¦æ¿€æ´»"),
    vectorization_status: Optional[VectorizationStatus] = Query(None, description="å‘é‡åŒ–çŠ¶æ€"),
    skip: int = Query(0, ge=0, description="è·³è¿‡æ•°é‡"),
    limit: int = Query(50, ge=1, le=1000, description="è¿”å›æ•°é‡"),
    session: Session = Depends(get_db_session)
):
    """è·å–èµ„æºåˆ—è¡¨"""
    try:
        from sqlalchemy import text
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = ["1=1"]
        params = {"skip": skip, "limit": limit}
        
        if resource_type:
            conditions.append("resource_type = :resource_type")
            params["resource_type"] = resource_type.value
        
        if is_active is not None:
            conditions.append("is_active = :is_active")
            params["is_active"] = is_active
        
        if vectorization_status:
            conditions.append("vectorization_status = :vectorization_status")
            params["vectorization_status"] = vectorization_status.value
        
        where_clause = " AND ".join(conditions)
        
        query = text(f"""
            SELECT id, resource_id, resource_name, resource_type, description,
                   capabilities, tags, metadata, is_active, status,
                   source_table, source_id, vectorization_status,
                   usage_count, success_rate, avg_response_time,
                   vector_updated_at, created_at, updated_at
            FROM resource_discovery.resource_registry
            WHERE {where_clause}
            ORDER BY created_at DESC
            OFFSET :skip LIMIT :limit
        """)
        
        result = session.execute(query, params)
        resources = []
        
        for row in result.fetchall():
            resource = ResourceRegistryResponse(
                id=row.id,
                resource_id=row.resource_id,
                resource_name=row.resource_name,
                resource_type=row.resource_type,
                description=row.description,
                capabilities=row.capabilities,
                tags=row.tags,
                metadata=row.metadata,
                is_active=row.is_active,
                status=row.status,
                source_table=row.source_table,
                source_id=row.source_id,
                vectorization_status=row.vectorization_status,
                usage_count=row.usage_count,
                success_rate=row.success_rate,
                avg_response_time=row.avg_response_time,
                vector_updated_at=row.vector_updated_at,
                created_at=row.created_at,
                updated_at=row.updated_at
            )
            resources.append(resource)
        
        return resources
        
    except Exception as e:
        logger.error(f"è·å–èµ„æºåˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–èµ„æºåˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/resources/{resource_id}", response_model=ResourceRegistryResponse)
async def get_resource(
    resource_id: str,
    session: Session = Depends(get_db_session)
):
    """è·å–å•ä¸ªèµ„æºè¯¦æƒ…"""
    try:
        from sqlalchemy import text
        
        query = text("""
            SELECT id, resource_id, resource_name, resource_type, description,
                   capabilities, tags, metadata, is_active, status,
                   source_table, source_id, vectorization_status,
                   usage_count, success_rate, avg_response_time,
                   vector_updated_at, created_at, updated_at
            FROM resource_discovery.resource_registry
            WHERE resource_id = :resource_id
        """)
        
        result = session.execute(query, {"resource_id": resource_id})
        row = result.fetchone()
        
        if not row:
            raise HTTPException(status_code=404, detail=f"èµ„æºä¸å­˜åœ¨: {resource_id}")
        
        resource = ResourceRegistryResponse(
            id=row.id,
            resource_id=row.resource_id,
            resource_name=row.resource_name,
            resource_type=row.resource_type,
            description=row.description,
            capabilities=row.capabilities,
            tags=row.tags,
            metadata=row.metadata,
            is_active=row.is_active,
            status=row.status,
            source_table=row.source_table,
            source_id=row.source_id,
            vectorization_status=row.vectorization_status,
            usage_count=row.usage_count,
            success_rate=row.success_rate,
            avg_response_time=row.avg_response_time,
            vector_updated_at=row.vector_updated_at,
            created_at=row.created_at,
            updated_at=row.updated_at
        )
        
        return resource
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–èµ„æºè¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–èµ„æºè¯¦æƒ…å¤±è´¥: {str(e)}")


@router.post("/sync", response_model=dict)
async def sync_resources(
    force_full_sync: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥")
):
    """å¯åŠ¨å¼‚æ­¥èµ„æºåŒæ­¥ä»»åŠ¡"""
    try:
        logger.info(f"ğŸ”„ å¯åŠ¨å¼‚æ­¥èµ„æºåŒæ­¥: force_full={force_full_sync}")

        # å¯¼å…¥ä»»åŠ¡å‡½æ•°
        from src.tasks.resource_discovery_tasks import sync_resources_task

        # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        task = sync_resources_task.delay(force_full_sync)

        logger.info(f"âœ… åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨: {task.id}")

        return {
            "success": True,
            "message": "èµ„æºåŒæ­¥ä»»åŠ¡å·²å¯åŠ¨",
            "task_id": task.id,
            "status": "started",
            "force_full_sync": force_full_sync
        }

    except Exception as e:
        logger.error(f"å¯åŠ¨èµ„æºåŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨èµ„æºåŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.get("/sync/status/{task_id}", response_model=dict)
async def get_sync_task_status(task_id: str):
    """è·å–åŒæ­¥ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦"""
    try:
        from src.celery_app import celery_app

        # è·å–ä»»åŠ¡çŠ¶æ€
        task = celery_app.AsyncResult(task_id)

        if task.state == 'PENDING':
            response = {
                "success": True,
                "task_id": task_id,
                "status": "pending",
                "message": "ä»»åŠ¡ç­‰å¾…æ‰§è¡Œä¸­...",
                "progress": 0
            }
        elif task.state == 'PROGRESS':
            response = {
                "success": True,
                "task_id": task_id,
                "status": "running",
                "message": task.info.get('message', 'ä»»åŠ¡æ‰§è¡Œä¸­...'),
                "progress": task.info.get('progress', 0),
                "current_step": task.info.get('current_step', ''),
                "total_steps": task.info.get('total_steps', 0),
                "processed_items": task.info.get('processed_items', 0),
                "total_items": task.info.get('total_items', 0)
            }
        elif task.state == 'SUCCESS':
            result = task.result
            response = {
                "success": True,
                "task_id": task_id,
                "status": "completed",
                "message": "åŒæ­¥ä»»åŠ¡å®Œæˆ",
                "progress": 100,
                "result": result
            }
        elif task.state == 'FAILURE':
            response = {
                "success": False,
                "task_id": task_id,
                "status": "failed",
                "message": f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(task.info)}",
                "progress": 0,
                "error": str(task.info)
            }
        else:
            response = {
                "success": True,
                "task_id": task_id,
                "status": task.state.lower(),
                "message": f"ä»»åŠ¡çŠ¶æ€: {task.state}",
                "progress": 0
            }

        return response

    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@router.post("/vectorize", response_model=BatchVectorizationResponse)
async def vectorize_resources(
    request: BatchVectorizationRequest,
    session: Session = Depends(get_db_session)
):
    """æ‰¹é‡å‘é‡åŒ–èµ„æº"""
    try:
        start_time = datetime.utcnow()
        
        logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡å‘é‡åŒ–: {len(request.resource_ids)} ä¸ªèµ„æº")
        
        # è·å–èµ„æºä¿¡æ¯
        from sqlalchemy import text
        
        resource_ids_str = "', '".join(request.resource_ids)
        query = text(f"""
            SELECT resource_id, resource_name, resource_type, description,
                   capabilities, tags, metadata
            FROM resource_discovery.resource_registry
            WHERE resource_id IN ('{resource_ids_str}')
        """)
        
        result = session.execute(query)
        resources = []
        
        for row in result.fetchall():
            resource = {
                "resource_id": row.resource_id,
                "resource_name": row.resource_name,
                "resource_type": row.resource_type,
                "description": row.description,
                "capabilities": row.capabilities,
                "tags": row.tags,
                "metadata": row.metadata
            }
            resources.append(resource)
        
        # æ‰§è¡Œå‘é‡åŒ–
        vectorized_results = await vectorizer.batch_vectorize_resources(session, resources)
        
        # ç»Ÿè®¡ç»“æœ
        successful_count = sum(1 for r in vectorized_results if r.get("vectorization_status") == "completed")
        failed_count = len(vectorized_results) - successful_count
        
        processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000
        
        response = BatchVectorizationResponse(
            total_resources=len(request.resource_ids),
            successful_resources=successful_count,
            failed_resources=failed_count,
            results=[],  # ç®€åŒ–è¿”å›ç»“æœ
            total_processing_time_ms=processing_time,
            timestamp=datetime.utcnow()
        )
        
        logger.info(f"âœ… æ‰¹é‡å‘é‡åŒ–å®Œæˆ: æˆåŠŸ {successful_count}, å¤±è´¥ {failed_count}")
        return response
        
    except Exception as e:
        logger.error(f"æ‰¹é‡å‘é‡åŒ–å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å‘é‡åŒ–å¤±è´¥: {str(e)}")


@router.get("/status", response_model=List[SystemStatus])
async def get_system_status(
    operation_type: Optional[OperationType] = Query(None, description="æ“ä½œç±»å‹"),
    status: Optional[SystemStatusType] = Query(None, description="çŠ¶æ€"),
    limit: int = Query(10, ge=1, le=100, description="è¿”å›æ•°é‡"),
    session: Session = Depends(get_db_session)
):
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        from sqlalchemy import text
        
        conditions = ["1=1"]
        params = {"limit": limit}
        
        if operation_type:
            conditions.append("operation_type = :operation_type")
            params["operation_type"] = operation_type.value
        
        if status:
            conditions.append("status = :status")
            params["status"] = status.value
        
        where_clause = " AND ".join(conditions)
        
        query = text(f"""
            SELECT id, operation_type, status, total_items, successful_items,
                   failed_items, error_message, result_data, started_at,
                   completed_at, duration_seconds, created_at, updated_at
            FROM resource_discovery.system_status
            WHERE {where_clause}
            ORDER BY created_at DESC
            LIMIT :limit
        """)
        
        result = session.execute(query, params)
        statuses = []
        
        for row in result.fetchall():
            status_obj = SystemStatus(
                id=row.id,
                operation_type=row.operation_type,
                status=row.status,
                total_items=row.total_items,
                successful_items=row.successful_items,
                failed_items=row.failed_items,
                error_message=row.error_message,
                result_data=row.result_data,
                started_at=row.started_at,
                completed_at=row.completed_at,
                duration_seconds=row.duration_seconds,
                created_at=row.created_at,
                updated_at=row.updated_at
            )
            statuses.append(status_obj)
        
        return statuses
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/change-detection", response_model=dict)
async def detect_resource_changes(
    preview_only: bool = Query(True, description="æ˜¯å¦ä»…é¢„è§ˆå˜æ›´"),
    session: Session = Depends(get_db_session)
):
    """æ£€æµ‹èµ„æºå˜æ›´"""
    try:
        logger.info(f"ğŸ” å¼€å§‹æ£€æµ‹èµ„æºå˜æ›´ (é¢„è§ˆæ¨¡å¼: {preview_only})")

        # ä½¿ç”¨èµ„æºå‘ç°æœåŠ¡æ£€æµ‹å˜æ›´
        changes = await discovery_service.detect_resource_changes(session, preview_only)

        # ç»Ÿè®¡å˜æ›´
        added_count = len(changes.get('added', []))
        modified_count = len(changes.get('modified', []))
        deleted_count = len(changes.get('deleted', []))
        total_changes = added_count + modified_count + deleted_count

        response = {
            "success": True,
            "preview_only": preview_only,
            "total_changes": total_changes,
            "change_summary": {
                "added_count": added_count,
                "modified_count": modified_count,
                "deleted_count": deleted_count
            },
            "changes": changes,
            "timestamp": datetime.utcnow().isoformat()
        }

        logger.info(f"âœ… å˜æ›´æ£€æµ‹å®Œæˆ: æ–°å¢{added_count}, ä¿®æ”¹{modified_count}, åˆ é™¤{deleted_count}")
        return response

    except Exception as e:
        logger.error(f"âŒ æ£€æµ‹èµ„æºå˜æ›´å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€æµ‹èµ„æºå˜æ›´å¤±è´¥: {str(e)}")


@router.post("/discover", response_model=dict)
async def discover_resources_manual():
    """æ‰‹åŠ¨å‘ç°ç³»ç»Ÿèµ„æº"""
    try:
        logger.info("ğŸ” æ‰‹åŠ¨å‘ç°ç³»ç»Ÿèµ„æº")

        # è·å–æ•°æ®åº“ä¼šè¯
        session = next(get_db_session())

        try:
            # åˆå§‹åŒ–å‘ç°æœåŠ¡
            discovery_service = ResourceDiscoveryService()

            # å‘ç°æ‰€æœ‰èµ„æº
            discovered_resources = await discovery_service.discover_all_resources(session)

            # è·å–å·²æ³¨å†Œçš„èµ„æº
            existing_query = text("""
                SELECT resource_id, resource_name, resource_type, vectorization_status,
                       created_at, updated_at
                FROM resource_discovery.resource_registry
                WHERE is_active = true
            """)

            result = session.execute(existing_query)
            existing_resources = [dict(row._mapping) for row in result.fetchall()]

            # åˆ†æèµ„æºçŠ¶æ€
            existing_ids = {r['resource_id'] for r in existing_resources}
            discovered_ids = {r['resource_id'] for r in discovered_resources}

            new_resources = [r for r in discovered_resources if r['resource_id'] not in existing_ids]
            missing_resources = [r for r in existing_resources if r['resource_id'] not in discovered_ids]
            existing_discovered = [r for r in discovered_resources if r['resource_id'] in existing_ids]

            # ç»Ÿè®¡å‘é‡åŒ–çŠ¶æ€
            vectorization_stats = {}
            for status in ['pending', 'in_progress', 'completed', 'failed']:
                count = len([r for r in existing_resources if r.get('vectorization_status') == status])
                vectorization_stats[status] = count

            return {
                "success": True,
                "message": f"å‘ç°äº† {len(discovered_resources)} ä¸ªèµ„æº",
                "discovery_summary": {
                    "total_discovered": len(discovered_resources),
                    "new_resources": len(new_resources),
                    "existing_resources": len(existing_discovered),
                    "missing_resources": len(missing_resources),
                    "vectorization_stats": vectorization_stats
                },
                "resources": {
                    "new": new_resources[:10],  # é™åˆ¶è¿”å›æ•°é‡
                    "existing": existing_discovered[:10],
                    "missing": missing_resources[:10]
                },
                "timestamp": datetime.utcnow().isoformat()
            }

        finally:
            session.close()

    except Exception as e:
        logger.error(f"æ‰‹åŠ¨èµ„æºå‘ç°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰‹åŠ¨èµ„æºå‘ç°å¤±è´¥: {str(e)}")


@router.post("/incremental-sync", response_model=dict)
async def incremental_sync(
    force_full_sync: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶å…¨é‡åŒæ­¥"),
    async_mode: bool = Query(True, description="æ˜¯å¦å¼‚æ­¥æ‰§è¡Œ")
):
    """å¢é‡åŒæ­¥èµ„æº"""
    try:
        logger.info(f"ğŸ”„ å¯åŠ¨å¢é‡åŒæ­¥: force_full={force_full_sync}, async={async_mode}")

        if async_mode:
            # å¼‚æ­¥æ¨¡å¼ï¼šå¯åŠ¨åå°ä»»åŠ¡
            from src.tasks.resource_discovery_tasks import incremental_sync_task
            task = incremental_sync_task.delay(force_full_sync)

            return {
                "success": True,
                "message": "å¢é‡åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨",
                "task_id": task.id,
                "status": "started",
                "force_full_sync": force_full_sync,
                "async_mode": True
            }
        else:
            # åŒæ­¥æ¨¡å¼ï¼šç›´æ¥æ‰§è¡Œ
            start_time = datetime.utcnow()

            # æ‰§è¡Œå¢é‡åŒæ­¥
            result = await synchronizer.incremental_sync(force_full_sync)

            processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000

            return {
                "success": True,
                "message": "å¢é‡åŒæ­¥å®Œæˆ",
                "result": result,
                "processing_time_ms": processing_time,
                "force_full_sync": force_full_sync,
                "async_mode": False,
                "timestamp": datetime.utcnow().isoformat()
            }

    except Exception as e:
        logger.error(f"âŒ å¢é‡åŒæ­¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¢é‡åŒæ­¥å¤±è´¥: {str(e)}")


@router.get("/statistics", response_model=dict)
async def get_statistics(
    session: Session = Depends(get_db_session)
):
    """è·å–èµ„æºå‘ç°ç»Ÿè®¡ä¿¡æ¯"""
    try:
        from sqlalchemy import text

        # èµ„æºç»Ÿè®¡
        resource_stats_query = text("""
            SELECT
                resource_type,
                COUNT(*) as total_count,
                COUNT(*) FILTER (WHERE is_active = true) as active_count,
                COUNT(*) FILTER (WHERE vectorization_status = 'completed') as vectorized_count
            FROM resource_discovery.resource_registry
            GROUP BY resource_type
        """)

        resource_result = session.execute(resource_stats_query)
        resource_stats = {}

        for row in resource_result.fetchall():
            resource_stats[row.resource_type] = {
                "total": row.total_count,
                "active": row.active_count,
                "vectorized": row.vectorized_count
            }

        # åŒ¹é…ç»Ÿè®¡
        match_stats_query = text("""
            SELECT
                COUNT(*) as total_queries,
                AVG(response_time) as avg_response_time,
                COUNT(*) FILTER (WHERE user_feedback = 'positive') as positive_feedback,
                COUNT(*) FILTER (WHERE user_feedback = 'negative') as negative_feedback
            FROM resource_discovery.resource_match_history
            WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
        """)

        match_result = session.execute(match_stats_query)
        match_row = match_result.fetchone()

        match_stats = {
            "total_queries": match_row.total_queries or 0,
            "avg_response_time": float(match_row.avg_response_time or 0),
            "positive_feedback": match_row.positive_feedback or 0,
            "negative_feedback": match_row.negative_feedback or 0
        }

        return {
            "resource_statistics": resource_stats,
            "match_statistics": match_stats,
            "last_updated": datetime.utcnow().isoformat()
        }

    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.get("/health", response_model=dict)
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        from src.config.resource_discovery import get_resource_discovery_config
        from src.services.resource_discovery.config_validator import ConfigValidator
        from src.services.resource_discovery.trigger_manager import TriggerManager

        config = get_resource_discovery_config()

        # æ£€æŸ¥é…ç½®
        validator = ConfigValidator(config)
        validation_results = await validator.validate_all()

        # æ£€æŸ¥è§¦å‘å™¨çŠ¶æ€
        trigger_manager = TriggerManager(config)
        trigger_status = await trigger_manager.get_trigger_status()

        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        session = next(get_db_session())
        try:
            from sqlalchemy import text
            session.execute(text("SELECT 1"))
            db_healthy = True
        except Exception:
            db_healthy = False
        finally:
            session.close()

        overall_healthy = (
            validation_results.get("overall_valid", False) and
            db_healthy and
            (not config.enable_triggers or trigger_status.get("total_existing", 0) > 0)
        )

        return {
            "success": True,
            "healthy": overall_healthy,
            "components": {
                "configuration": validation_results.get("overall_valid", False),
                "database": db_healthy,
                "triggers": trigger_status.get("total_existing", 0) > 0 if config.enable_triggers else True,
                "resources": len(config.get_enabled_resources())
            },
            "message": "å¥åº·æ£€æŸ¥å®Œæˆ"
        }

    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "healthy": False,
            "error": str(e),
            "message": "å¥åº·æ£€æŸ¥å¤±è´¥"
        }
