# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
Text2SQLå·¥å…·

ä¸ºæ™ºèƒ½ä½“æä¾›è‡ªç„¶è¯­è¨€è½¬SQLæŸ¥è¯¢åŠŸèƒ½
"""

import json
import logging
import asyncio
from typing import Dict, Any, Optional, List, Annotated
from datetime import datetime

from langchain_core.tools import tool
from src.database import get_db_session
from src.tools.decorators import log_io
from src.services.text2sql import Text2SQLService
from src.models.text2sql import SQLGenerationRequest, SQLExecutionRequest

logger = logging.getLogger(__name__)


class ToolResult:
    """ç»Ÿä¸€çš„å·¥å…·è¿”å›å€¼ç»“æ„"""
    
    def __init__(
        self, 
        success: bool, 
        message: str, 
        data: Any = None, 
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        self.success = success
        self.message = message
        self.data = data
        self.error = error
        self.metadata = metadata or {}
        self.timestamp = datetime.now().isoformat()
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
        return json.dumps({
            "success": self.success,
            "message": self.message,
            "data": self.data,
            "error": self.error,
            "metadata": self.metadata,
            "timestamp": self.timestamp
        }, ensure_ascii=False, indent=2)


@tool
@log_io
def text2sql_query(
    question: Annotated[str, "è‡ªç„¶è¯­è¨€é—®é¢˜"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“IDï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤æ•°æ®åº“"] = None,
    execute_sql: Annotated[bool, "æ˜¯å¦æ‰§è¡Œç”Ÿæˆçš„SQL"] = True
) -> str:
    """
    æ‰§è¡ŒText2SQLæŸ¥è¯¢
    
    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢å¹¶å¯é€‰æ‹©æ‰§è¡Œã€‚
    æ”¯æŒæŒ‡å®šç›®æ ‡æ•°æ®åº“ï¼Œè¿”å›SQLè¯­å¥å’ŒæŸ¥è¯¢ç»“æœã€‚
    """
    try:
        logger.info(f"ğŸ” Text2SQLæŸ¥è¯¢: {question[:100]}...")
        
        # ä½¿ç”¨çœŸå®çš„Text2SQLæœåŠ¡
        text2sql_service = Text2SQLService()

        # åˆ›å»ºSQLç”Ÿæˆè¯·æ±‚
        request = SQLGenerationRequest(
            question=question,
            datasource_id=database_id or 1,  # ä½¿ç”¨é»˜è®¤æ•°æ®åº“ID
            include_explanation=True
        )

        # ç”ŸæˆSQL
        generation_result = asyncio.run(text2sql_service.generate_sql(request))

        generated_sql = generation_result.generated_sql
        confidence = generation_result.confidence_score
        explanation = generation_result.explanation or f"åŸºäºé—®é¢˜'{question}'ç”Ÿæˆçš„SQLæŸ¥è¯¢"
        
        if not execute_sql:
            return ToolResult(
                success=True,
                message="SQLç”ŸæˆæˆåŠŸ",
                data={
                    "sql": generated_sql,
                    "confidence": confidence,
                    "explanation": explanation
                },
                metadata={
                    "question": question,
                    "database_id": database_id,
                    "executed": False
                }
            ).to_json()
        
        # æ‰§è¡ŒSQL
        execution_request = SQLExecutionRequest(
            query_id=generation_result.query_id
        )

        execution_result = asyncio.run(text2sql_service.execute_sql(execution_request))

        if execution_result.status.value == "success":
            results = execution_result.result_data or []
            row_count = execution_result.result_rows or 0
        else:
            # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœä½†ä¿ç•™SQL
            results = []
            row_count = 0
        
        return ToolResult(
            success=True,
            message="Text2SQLæŸ¥è¯¢æˆåŠŸ",
            data={
                "sql": generated_sql,
                "confidence": confidence,
                "explanation": explanation,
                "results": results,
                "row_count": row_count
            },
            metadata={
                "question": question,
                "database_id": database_id,
                "execution_time": "0.05s",
                "executed": True
            }
        ).to_json()
    
    except Exception as e:
        logger.error(f"âŒ Text2SQLæŸ¥è¯¢å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="Text2SQLæŸ¥è¯¢è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"question": question, "database_id": database_id}
        ).to_json()


@tool
@log_io
def generate_sql_only(
    question: Annotated[str, "è‡ªç„¶è¯­è¨€é—®é¢˜"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“ID"] = None
) -> str:
    """
    ä»…ç”ŸæˆSQLè¯­å¥

    å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œä½†ä¸æ‰§è¡Œã€‚
    é€‚ç”¨äºéœ€è¦äººå·¥å®¡æ ¸SQLçš„åœºæ™¯ã€‚
    """
    try:
        logger.info(f"ğŸ”§ ç”ŸæˆSQL: {question[:100]}...")

        # ä½¿ç”¨çœŸå®çš„Text2SQLæœåŠ¡
        text2sql_service = Text2SQLService()

        # åˆ›å»ºSQLç”Ÿæˆè¯·æ±‚
        request = SQLGenerationRequest(
            question=question,
            datasource_id=database_id or 1,  # ä½¿ç”¨é»˜è®¤æ•°æ®åº“ID
            include_explanation=True
        )

        # ç”ŸæˆSQLï¼ˆä¸æ‰§è¡Œï¼‰
        generation_result = asyncio.run(text2sql_service.generate_sql(request))

        generated_sql = generation_result.generated_sql
        confidence = generation_result.confidence_score
        explanation = generation_result.explanation or f"åŸºäºé—®é¢˜'{question}'ç”Ÿæˆçš„SQLæŸ¥è¯¢"

        # è·å–ç›¸ä¼¼çš„SQLç¤ºä¾‹ä½œä¸ºå‚è€ƒ
        similar_examples = []
        try:
            # å°è¯•è·å–ç›¸ä¼¼çš„è®­ç»ƒç¤ºä¾‹
            from src.services.vanna.service_manager import vanna_service_manager
            vanna_result = asyncio.run(vanna_service_manager.generate_sql(
                datasource_id=database_id or 1,
                question=question
            ))

            if vanna_result.get("success") and vanna_result.get("similar_sqls"):
                similar_examples = vanna_result["similar_sqls"][:3]  # å–å‰3ä¸ªç›¸ä¼¼ç¤ºä¾‹

        except Exception as e:
            logger.warning(f"è·å–ç›¸ä¼¼ç¤ºä¾‹å¤±è´¥: {e}")

        return ToolResult(
            success=True,
            message="SQLç”ŸæˆæˆåŠŸ",
            data={
                "sql": generated_sql,
                "confidence": confidence,
                "explanation": explanation,
                "similar_examples": similar_examples,
                "generation_method": "text2sql_service"
            },
            metadata={
                "question": question,
                "database_id": database_id,
                "query_id": generation_result.query_id,
                "datasource_id": generation_result.datasource_id
            }
        ).to_json()

    except Exception as e:
        logger.error(f"âŒ SQLç”Ÿæˆå¼‚å¸¸: {e}")

        # å¦‚æœçœŸå®æœåŠ¡å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„å…³é”®è¯æ˜ å°„ä½œä¸ºåå¤‡
        try:
            logger.info("ä½¿ç”¨åå¤‡SQLç”Ÿæˆæ–¹æ³•...")

            # ç®€å•çš„å…³é”®è¯æ˜ å°„
            keywords_mapping = {
                "ç”¨æˆ·": "users",
                "è®¢å•": "orders",
                "äº§å“": "products",
                "é”€å”®": "sales",
                "åº“å­˜": "inventory",
                "è¡¨": "tables",
                "æ•°æ®åº“": "database"
            }

            table_name = "data"
            for keyword, table in keywords_mapping.items():
                if keyword in question:
                    table_name = table
                    break

            # ç”ŸæˆåŸºç¡€SQL
            if "ç»Ÿè®¡" in question or "æ•°é‡" in question or "æ€»è®¡" in question or "å¤šå°‘" in question:
                if "è¡¨" in question:
                    generated_sql = "SELECT COUNT(*) as table_count FROM information_schema.tables WHERE table_schema = DATABASE()"
                else:
                    generated_sql = f"SELECT COUNT(*) as total_count FROM {table_name}"
            elif "æœ€æ–°" in question or "æœ€è¿‘" in question:
                generated_sql = f"SELECT * FROM {table_name} ORDER BY created_at DESC LIMIT 10"
            elif "æ‰€æœ‰" in question or "å…¨éƒ¨" in question:
                if "è¡¨" in question:
                    generated_sql = "SELECT table_name FROM information_schema.tables WHERE table_schema = DATABASE() ORDER BY table_name"
                else:
                    generated_sql = f"SELECT * FROM {table_name} LIMIT 10"
            else:
                generated_sql = f"SELECT * FROM {table_name} LIMIT 10"

            confidence = 0.6  # é™ä½ç½®ä¿¡åº¦ï¼Œå› ä¸ºæ˜¯åå¤‡æ–¹æ³•
            explanation = f"ä½¿ç”¨å…³é”®è¯åˆ†æç”Ÿæˆçš„SQLæŸ¥è¯¢ï¼ˆåå¤‡æ–¹æ³•ï¼‰ï¼Œç›®æ ‡è¡¨: {table_name}"

            return ToolResult(
                success=True,
                message="SQLç”ŸæˆæˆåŠŸï¼ˆä½¿ç”¨åå¤‡æ–¹æ³•ï¼‰",
                data={
                    "sql": generated_sql,
                    "confidence": confidence,
                    "explanation": explanation,
                    "suggested_table": table_name,
                    "generation_method": "fallback_keyword_mapping"
                },
                metadata={
                    "question": question,
                    "database_id": database_id,
                    "fallback_reason": str(e)
                }
            ).to_json()

        except Exception as fallback_error:
            logger.error(f"âŒ åå¤‡SQLç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_error}")
            return ToolResult(
                success=False,
                message="SQLç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
                error=str(e),
                metadata={"question": question, "database_id": database_id}
            ).to_json()


@tool
@log_io
def get_training_examples(
    keyword: Annotated[Optional[str], "å…³é”®è¯è¿‡æ»¤"] = None,
    limit: Annotated[int, "è¿”å›æ•°é‡é™åˆ¶"] = 10
) -> str:
    """
    è·å–Text2SQLè®­ç»ƒç¤ºä¾‹
    
    ä»vanna_embeddingsè¡¨ä¸­è·å–è®­ç»ƒç¤ºä¾‹ï¼Œç”¨äºå‚è€ƒå’Œå­¦ä¹ ã€‚
    """
    try:
        logger.info(f"ğŸ“š è·å–è®­ç»ƒç¤ºä¾‹: keyword={keyword}, limit={limit}")
        
        session = next(get_db_session())
        
        try:
            from sqlalchemy import text
            
            # æ„å»ºæŸ¥è¯¢
            if keyword:
                query = text("""
                    SELECT question, content, sql_query 
                    FROM text2sql.vanna_embeddings 
                    WHERE question ILIKE :keyword OR content ILIKE :keyword
                    ORDER BY created_at DESC
                    LIMIT :limit
                """)
                result = session.execute(query, {"keyword": f"%{keyword}%", "limit": limit})
            else:
                query = text("""
                    SELECT question, content, sql_query 
                    FROM text2sql.vanna_embeddings 
                    ORDER BY created_at DESC
                    LIMIT :limit
                """)
                result = session.execute(query, {"limit": limit})
            
            examples = []
            for row in result.fetchall():
                example = {
                    "question": row.question,
                    "content": row.content,
                    "sql_query": row.sql_query
                }
                examples.append(example)
            
            return ToolResult(
                success=True,
                message=f"æ‰¾åˆ° {len(examples)} ä¸ªè®­ç»ƒç¤ºä¾‹",
                data={
                    "examples": examples,
                    "total_count": len(examples)
                },
                metadata={
                    "keyword_filter": keyword,
                    "limit": limit
                }
            ).to_json()
        
        finally:
            session.close()
    
    except Exception as e:
        logger.error(f"âŒ è·å–è®­ç»ƒç¤ºä¾‹å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="è·å–è®­ç»ƒç¤ºä¾‹è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"keyword": keyword, "limit": limit}
        ).to_json()


@tool
@log_io
def validate_sql(
    sql: Annotated[str, "è¦éªŒè¯çš„SQLè¯­å¥"],
    database_id: Annotated[Optional[int], "æ•°æ®åº“ID"] = None
) -> str:
    """
    éªŒè¯SQLè¯­å¥
    
    æ£€æŸ¥SQLè¯­å¥çš„è¯­æ³•æ­£ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œä¸æ‰§è¡ŒæŸ¥è¯¢ã€‚
    """
    try:
        logger.info(f"ğŸ” éªŒè¯SQL: {sql[:100]}...")
        
        # åŸºæœ¬çš„SQLå®‰å…¨æ£€æŸ¥
        dangerous_keywords = [
            "DROP", "DELETE", "UPDATE", "INSERT", "ALTER", 
            "CREATE", "TRUNCATE", "EXEC", "EXECUTE"
        ]
        
        sql_upper = sql.upper()
        found_dangerous = [kw for kw in dangerous_keywords if kw in sql_upper]
        
        if found_dangerous:
            return ToolResult(
                success=False,
                message="SQLåŒ…å«å±é™©æ“ä½œ",
                error=f"å‘ç°å±é™©å…³é”®è¯: {', '.join(found_dangerous)}",
                data={"sql": sql, "dangerous_keywords": found_dangerous}
            ).to_json()
        
        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
        if not sql.strip().upper().startswith("SELECT"):
            return ToolResult(
                success=False,
                message="åªæ”¯æŒSELECTæŸ¥è¯¢",
                error="SQLå¿…é¡»ä»¥SELECTå¼€å¤´",
                data={"sql": sql}
            ).to_json()
        
        # TODO: æ›´è¯¦ç»†çš„SQLè¯­æ³•éªŒè¯
        # å¯ä»¥é›†æˆSQLè§£æå™¨è¿›è¡Œæ›´ä¸¥æ ¼çš„éªŒè¯
        
        return ToolResult(
            success=True,
            message="SQLéªŒè¯é€šè¿‡",
            data={
                "sql": sql,
                "is_safe": True,
                "query_type": "SELECT"
            },
            metadata={
                "database_id": database_id,
                "validation_rules": ["å®‰å…¨å…³é”®è¯æ£€æŸ¥", "æŸ¥è¯¢ç±»å‹æ£€æŸ¥"]
            }
        ).to_json()
    
    except Exception as e:
        logger.error(f"âŒ SQLéªŒè¯å¼‚å¸¸: {e}")
        return ToolResult(
            success=False,
            message="SQLéªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸",
            error=str(e),
            metadata={"sql": sql, "database_id": database_id}
        ).to_json()
